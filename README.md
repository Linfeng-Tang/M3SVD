# M3SVD: Multi-Modal Multi-Scene Video Dataset

<div align="center">
  <p>
    <a href="https://arxiv.org/abs/2503.23359">
      <img src="https://img.shields.io/badge/Paper-CVPR%202026-blue" alt="Paper">
    </a>
    <a href="https://github.com/Linfeng-Tang/VideoFusion">
      <img src="https://img.shields.io/badge/Code-VideoFusion-green" alt="Code">
    </a>
    <a href="https://pan.baidu.com/s/1FhUirShTQ02N5Dl3pgl-PA?pwd=M2VD">
      <img src="https://img.shields.io/badge/Baidu-Images-2319DC?logo=baidu&logoColor=white" alt="Baidu Images">
    </a>
    <a href="https://pan.baidu.com/s/1R6HOSMXCHSiPEywU0GK_hw?pwd=M2VD">
      <img src="https://img.shields.io/badge/Baidu-Videos-2319DC?logo=baidu&logoColor=white" alt="Baidu Videos">
    </a>
    <a href="https://pan.baidu.com/s/1R6HOSMXCHSiPEywU0GK_hw?pwd=M2VD">
      <img src="https://img.shields.io/badge/GoogleDrive-Videos-4285F4?logo=googledrive&logoColor=white" alt="GoogleDrive Videos">
    </a>
  </p>
</div>
## üì¶ Notes on Provided Formats (Images vs. Videos)
- **Images** are released in the **native per-frame format** that is **directly used by the VideoFusion project** (i.e., frame sequences under each clip folder), so you can plug them into the training/testing pipeline without any extra conversion.
- **Videos** are additionally provided by **packing each frame sequence into a single video file** (e.g., `.mp4`) to **reduce file count** and **avoid storage / hosting limitations** (many platforms struggle with extremely large numbers of small image files).

## üßæ Folder Meaning
We provide both **high-quality (clean/enhanced)** data and **degraded** data for infrared and visible modalities:

- **infrared_Enhance**: **High-quality infrared (IR)** frames (clean/enhanced version).
- **visible_Enhance**: **High-quality visible (VI)** frames (clean/enhanced version).
- **infrared_noise**: **Degraded infrared (IR)** frames with **stripe noise** (a typical IR sensor degradation).
- **visible_Blur**: **Degraded visible (VI)** frames with **blur** (e.g., motion/defocus blur).
---

## ‚ú® News  

- **[2026]** Our paper **‚ÄúVideoFusion: A Spatio-Temporal Collaborative Network for Multi-modal Video Fusion and Restoration‚Äù** has been accepted to **CVPR 2026**.  [[Paper](https://arxiv.org/abs/2503.23359)] [[Code](https://github.com/Linfeng-Tang/VideoFusion)]

- **[2025]** [**M3SVD**](https://github.com/Linfeng-Tang/M3SVD) dataset is officially released.

---

# üìñ Introduction

**M3SVD (Multi-Modal Multi-Scene Video Dataset)** is a large-scale infrared-visible (IR-VI) video dataset designed for:

- üî• Multi-modal video fusion  
- üåô Low-light / degraded video restoration  
- üìπ Spatio-temporal modeling research  

---

# üé• Scenario Schematic

<p align="center">
  <img src="Video/Demo/datasets.png" width="92%">
</p>
<p align="center">
  <i>Visualization of representative scenarios in M3SVD. 
    The dataset contains 220 temporally synchronized infrared-visible (IR-VI) video pairs 
    with 153,797 aligned frames in total, captured at a resolution of 640√ó480 and 30 FPS.</i>
</p>

---

# üèó Data Processing Workflow
<p align="center">
  <img src="assets/Workflow.jpg" width="92%">
</p>

# Dataset Comparison (vs. prior works)
<p align="center">
  <img src="assets/Dataset_Comparison.jpg" width="92%">
</p>


---

# üéû Video Demo

Example sequences (GIF previews):

![Demo GIF](Video/Demo/0118_1803.gif)

![Demo GIF](Video/Demo/1230_1154.gif)

![Demo GIF](Video/Demo/0114_1551.gif)

![Demo GIF](Video/Demo/0115_1831.gif)

---

# üì¶ Dataset Availability

- Current release: **Test split**
- Full dataset access: Please contact  
  **linfeng0419@gmail.com**

We are open to academic collaboration and research usage.

---

# üîó Related Work Using M3SVD

### [VideoFusion](https://arxiv.org/abs/2503.23359) (CVPR 2026)
Spatio-temporal collaborative network for multi-modal video fusion and restoration.  [[Paper](https://arxiv.org/abs/2503.23359)] [[Code](https://github.com/Linfeng-Tang/VideoFusion)]

---

# üìù Citation

If you use M3SVD in your research, please cite:

```bibtex
@inproceedings{Tang2026VideoFusion,
  title     = {VideoFusion: A Spatio-Temporal Collaborative Network for Multi-modal Video Fusion and Restoration},
  author    = {Tang, Linfeng and Wang, Yeda and Gong, Meiqi and Li, Zizhuo and Deng, Yuxin and Yi, Xunpeng and Li, Chunyu and Zhang, Hao and Xu, Han and Ma, Jiayi},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2026}
}
